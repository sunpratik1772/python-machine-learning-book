beeline -u "jdbc:hive2://dwbdtest1r2m3.wellpoint.com:10000/default;principal=hive/_HOST@DEVAD.WELLPOINT.COM;sasl.Qop=auth-conf"  -f drop_main.sh 
beeline -u "jdbc:hive2://dwbdtest1r2m3.wellpoint.com:10000/default;principal=hive/_HOST@DEVAD.WELLPOINT.COM;sasl.Qop=auth-conf" -f drop_tb_eftr_rn_oo_new.sql
beeline -u "jdbc:hive2://dwbdtest1r2m3.wellpoint.com:10000/default;principal=hive/_HOST@DEVAD.WELLPOINT.COM;sasl.Qop=auth-conf" -f drop_tb_eftr_rn_new.sql
hadoop fs -rmr /hdfsdata/vs1/isg/adva/no_phi/no_gbd/warehouse/Restated_Membership
/home/ad69135/af08765/preprocess_folder_deletion.sh 


/home/ad69135/af08765/one-time-load.sh  201601 201612 &


spark-submit --class com.supratik.restatedMembership.module1.test --master yarn --deploy-mode cluster --conf spark.yarn.executor.memoryOverhead=600 \
--driver-memory 12G --executor-memory 4096M --num-executors 30   --conf spark.network.timeout=800s --executor-cores 3  prepro.jar "2017" "201701" "restated_spark_jan" 


/home/ad69135/af08765/main_sqoop_new.sh
/home/ad69135/af08765/preprocess_folder_creation.sh 


nohup ./rner_new.sh 


nohup ./runner2.sh


echo "show tables like 'rs_ja_15_enrol_*';" > tables.sql
beeline -u "jdbc:hive2://dwbdtest1r2m3.wellpoint.com:10000/default;principal=hive/_HOST@DEVAD.WELLPOINT.COM;sasl.Qop=auth-conf"  -f tables.sql  > tables.txt 

python generate_droptables.py
beeline -u "jdbc:hive2://dwbdtest1r2m3.wellpoint.com:10000/default;principal=hive/_HOST@DEVAD.WELLPOINT.COM;sasl.Qop=auth-conf" -f droptables.sql