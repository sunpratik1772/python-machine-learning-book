'''
Created on Dec 14, 2015

@author: Supratik.Datta
'''
import os
import re
import datetime
import csv
from collections import defaultdict
from lib.voluptuous import Schema, Required, All, Length, Range, MultipleInvalid, Invalid, Any
from itertools import islice
import ast
import decimal
import  logging
from time import gmtime, strftime


from src.python.common.config_reader import property_reader
from datetime import date



def validate_format(param1):
#     print param1
    def f(v):
#         print param1, v
        if re.match(str(param1), str(v)):
            return str(v)
        else:
            raise Invalid("Data format invalid")
    return f

def Date(msg=None):
    def f(datestring):
        if datetime.datetime.strptime(datestring, '%d/%m/%Y'):
            return datestring
        else:
            raise ValueError(msg or ("incorrect Date"))
    return f

def Time(msg=None):
    def f(datestring):
        if datetime.datetime.strptime(datestring, '%H:%M:%S'):
            return datestring
        else:
            raise ValueError(msg or ("incorrect Time"))
    return f



def Decimal(min_wstr,max_wstr):
    def f(v):

        try:
            if decimal.Decimal(str(v)):
                if int(min_wstr)<decimal.Decimal(str(v))<=int(max_wstr):
                    return str(v)
                else:
                    raise Invalid("Value out of accepted range")                    
        except decimal.InvalidOperation:
            raise Invalid("Value should be decimal")
    return f



def get_key_constraint(field_constraints):
    
    if str.upper(field_constraints['validation_required']) == 'YES' : 
        field_name = field_constraints['field_name']
        return Required(field_name)
    else : 
        field_name = field_constraints['field_name']
        return (field_name)
    
def get_column_name(data_path):


    
    columns = defaultdict(list) # each value in each column is appended to a list
    
    with open(data_path) as f:
        reader = csv.DictReader(f) # read rows into a dictionary format
        for row in reader: # read a row as {column1: value1, column2: value2,...}
            for (k,v) in row.items(): # go over each column name and value 
                columns[k].append(v) # append the value into the appropriate list
    Field_Name = columns['field_name']
    return Field_Name



def get_val_constraint(field_constraints):
     
    if str.upper(field_constraints['data_type']) == 'INT' :
        
        min_str = field_constraints['min_val']
        max_str = field_constraints['max_val']
        
        if str.upper(min_str) != 'NA' and str.upper(max_str) != 'NA' :
            min_val = int(min_str)
            max_val = int(max_str)
#             if str.upper(field_constraints['null_allowed'])== 'YES':
#                 return Any(All(int, Range(min=min_val, max=max_val)),All(Any(('null'),('NULL')))),
            if str.upper(field_constraints['can_be_empty'])== 'YES':
                return Any(All(int,Range(min=min_val, max=max_val)),All('')),
            else:    
                return All(int,Range(min=min_val,max=max_val))
        else :   
#             if str.upper(field_constraints['null_allowed'])== 'YES':
#                 return Any(All(int,('NULL')))
            if str.upper(field_constraints['can_be_empty'])== 'YES':
                return Any(All(int,All('')))
            else:                      
                return All(int)
        
    if str.upper(field_constraints['data_type']) == 'DECIMAL' :
        min_wstr = field_constraints['min_val']
        max_wstr = field_constraints['max_val']
#         if str.upper(field_constraints['null_allowed'])== 'YES':
#             return Any(All(Decimal(min_wstr,max_wstr)),All(Any(('null'),('NULL')))),
        if str.upper(field_constraints['can_be_empty'])== 'YES':
            return Any(All(Decimal(min_wstr,max_wstr)),All('')),
        else:  
            return All(Decimal(min_wstr,max_wstr))
    
        
    elif str.upper(field_constraints['data_type']) == 'VARCHAR' :

        if field_constraints['data_format'] : # has specific format
            param1 = field_constraints['data_format']
            print param1
#             if str.upper(field_constraints['null_allowed'])== 'YES':
#                 return Any(All(validate_format(param1)),All(Any(('null'),('NULL')))),
#             if str.upper(field_constraints['can_be_empty'])== 'YES':
#                 return Any(All(validate_format(param1)),All('')),
#             else:  
            return All(validate_format(param1))
        else :
            data_len = field_constraints['data_length']
            
            if str.upper(data_len) != 'NA' :
                data_length = int(data_len)
#                 if str.upper(field_constraints['null_allowed'])== 'YES':
#                     return Any(All(str, Length(max=data_length)),int,float,All(Any(('null'),('NULL'))))
                if str.upper(field_constraints['can_be_empty'])== 'YES':
                    return Any(All(str, Length(max=data_length)),int,float,All('')),
                else:
                    return Any(All(str,Length(max=data_length)),int,float)
            else : 
#                 if str.upper(field_constraints['null_allowed'])== 'YES':
#                     return Any(All(str,int,float,All(Any(('null'),('NULL')))))
                if str.upper(field_constraints['can_be_empty'])== 'YES':
                    return Any(All(str,int,float,All(''))),
                else:                          
                    return Any(str,int,float)
                
    elif str.upper(field_constraints['data_type']) == 'DATE' :
        if str.upper(field_constraints['can_be_empty'])== 'YES':
            return Any(All(Date()),All('')),
        else:
            return All(Date())   

                      
            
    elif str.upper(field_constraints['data_type']) == 'TIME' :
        if str.upper(field_constraints['can_be_empty'])== 'YES':
            return Any(Time(()),All('')),
        else:
            return All(Time())  
          
            



def get_schema_validaor(schema_file_path):
    schema_file = open(schema_file_path)
    reader = csv.DictReader(schema_file)
    
    schema_dist= {}
    
    for field_constraint_dict in reader: 
        #print field_constraint_dict
        
#         if str.upper(field_constraint_dict['validation_required']) == 'YES':
        key = get_key_constraint(field_constraint_dict)
        val = get_val_constraint(field_constraint_dict)
        schema_dist[key] = val
#         results = [ item['email'] for item in schema_dist ]
        
    #print schema_dist
     
    schema_validator = Schema(schema_dist)
    
    return schema_validator

def get_data_cursor(csvFile,delimiter, fieldnames):
    """
    Convert csv rows into an array of dictionaries
    All data types are automatically checked and converted
    """
    cursor = []  # Placeholder for the dictionaries/documents
    with open(csvFile) as csvFile:
        for row in islice(csvFile, 0, None):
            
            values = list(row.strip('\n').split(delimiter))
#             if values.startswith('^') and values.endswith('^'):
#                 values = values[1:-1]
            print values

            for i, value in enumerate(values):
                print value
                try:
                    nValue = ast.literal_eval(value)
                    values[i] = nValue
                except (ValueError,SyntaxError) as error:
                    values[i] = value
            cursor.append(dict(zip(fieldnames, values)))
    return cursor


def validate_data(csvFile,delimiter,quotechar,fieldnames,schema_validator,feedName):
    logger = logging.getLogger("validate_data")
    logger.info("Starting data validation ")
    errorFile =csvFile.replace(os.path.basename(csvFile),feedName+'_error_records.txt')
    mode ='a'
    issues = {}  
    with open(csvFile) as csvFile:
        line_number = 0
        for row in islice(csvFile, 0, None):
            line_number+=1
            row = row.strip()
            if quotechar :
                row = row.lstrip(quotechar)
                pattern = quotechar+"{1}$"
                if quotechar == '^':                
                    pattern = "\\" + pattern
                    
                row = re.sub(pattern,'',row)
            values = list(row.split(delimiter))
            #values = map(lambda each:each.strip("^"), val)
            for i, value in enumerate(values):
                    try:
                        nValue = ast.literal_eval(value)
                        values[i] = nValue
                    except (ValueError,SyntaxError) as error:
                        values[i] = value
            line_dist = dict(zip(fieldnames, values))
            try:
                if line_number % 1000 == 0 :
                    msg = "Validating line number " + str(line_number)
                    if line_number % 10000 == 0 :
                    	print msg
                    logger.info(msg)
                schema_validator(line_dist)
            except MultipleInvalid as e :
                message = str(e)
                #print 'Validation failed in line number ', str(line_number)
                #if feed type is oyster event or profile capture first two field in a new file
                if feedName == 'oyster_profile':
                    if os.path.exists(errorFile):
                        mode ='a'
                    else:
                        mode ='w'
                    with open(errorFile,mode) as errorRecords:
                        errorRecords.write(values[0]+""+values[1]+'\n') 
                        
                field_name,issue_key =  get_field_name_and_issue_key(message)
                
                if field_name  not in issues:
                    issues[field_name] = {}
                
                inner_map = issues[field_name]
                
                if issue_key not in inner_map:
                    inner_map [issue_key] = []
                
                inner_map[issue_key].append(line_number)
                    
                #issues.append(('Line Number : '+str(line_number),message))    
        print 'Total number of Validation Issues', len(issues)

    return issues

def get_field_name_and_issue_key(message):
    
    match = re.search('(.+?)for dictionary', message)
   
    if match :
        key = match.group(1) 
    else :
        key = "unknown message" 
   
    match = re.search('\[\'(.+?)\'\]', message)
    if match :
        field_name = match.group(1) 
    else :
        field_name = "unknown" 
    
    return field_name, key
   
def find_between( s, first, last ):
    try:
        start = s.index( first ) + len( first )
        end = s.index( last, start )
        return s[start:end]
    except ValueError:
        return "unknown"

def do_schema_validation(schema_validator,data_reader):  
    logger = logging.getLogger("do_schema_validation")
    logger.info("Starting schema validation ")    
    validation_issues = []
    line_number = 0
    for line_dist in data_reader:
        line_number+=1
        #print line_dist
        try:
            schema_validator(line_dist)
        except MultipleInvalid as e :
            message = str(e)
            validation_issues.append(('Line Number : '+str(line_number),message))        
    
#     print 'Total number of Validation Issues', len(validation_issues)
#     print 'Following lines have validation issues: '
    for issue in validation_issues:
        print issue
#     return len(validation_issues)
    

            
def validate_against_schema(feed_properties,source_file_path):
    logger = logging.getLogger("schema_validator")
    logger.info("Starting validation process for "+source_file_path)

    schema_loc = feed_properties.get_value('schema_location')
#    schema_version = feed_properties.get_value('schema_version')

    no_of_schemas = feed_properties.get_value('no_of_schema_versions')
    for x in range(1, int(no_of_schemas)+1): 
        version= 'schema_version'+str(x)
        start_date =feed_properties.get_value(version+'_start_date')
        end_date =feed_properties.get_value(version+'_end_date')     
        current_date = strftime("%m/%d/%Y", gmtime())
        print datetime.datetime.strptime(start_date, '%m/%d/%Y')
        if datetime.datetime.strptime(start_date, '%m/%d/%Y') < datetime.datetime.strptime(str(current_date), '%m/%d/%Y') < datetime.datetime.strptime(end_date, '%m/%d/%Y') :
            schema_version = feed_properties.get_value(version)
            print schema_version
    schema_path = os.path.join(schema_loc + "_" + schema_version+ ".csv")
    quoting_chars = feed_properties.get_value('quoting_chars')
    delimiter = feed_properties.get_value('delimiter')    
    schema_validator = get_schema_validaor(schema_path)
    feedName = feed_properties.get_value('source_feed_type') 
    threshold_limit = feed_properties.get_value('tolarance_limit')
    #reader = get_data_reader("data_1.csv")
    headers=get_column_name(schema_path)
    
   
    print 'Starting schema validation for file '+ source_file_path
    print 'Schema file path is '+ schema_path
    print 'headers : ' + str(headers) 
    print datetime.datetime.now()
    #issues = validate_data("oyster_profile.D2015320",",",headers,schema_validator)
    issues = validate_data(source_file_path,delimiter,quoting_chars,headers,schema_validator,feedName)
    print datetime.datetime.now()
   
    print 'Number of issues'+ str(len(issues))
 
    if len(issues) <= 0:
        return 'ok','Schema validation successful'
    elif len(issues)>0 and len(issues)<= threshold_limit:
        msg = log_issues_and_get_schema_validation_summary(issues)
        return 'under threshold limit',msg
    else :
        msg = log_issues_and_get_schema_validation_summary(issues)
        
        return 'error',msg

        
def log_issues_and_get_schema_validation_summary(issues):
    logger = logging.getLogger("schema_validator")
    
    message = 'Following issues found during data validation against schema '
    
    for field_name,details in issues.items() : 
        field_details = '\nFor field "'+field_name + '" : '
        message += field_details
        
        for issue,lineNumbers in details.items():
            detail = str(issue)+"at line no = " +  get_string_from_list(lineNumbers)
            message += detail       
        
        
    logger.warning("\n"+message)
    
    if len(message) <= 10000:
        return message
    else:
        msg = message[:9900]
        final = msg + '  ... There are more issues! please see logs for details'
        return final

def get_string_from_list(list_str):
    
    mystr = ''
    first = True
    
    for el in list_str :
        
        if not first :
            mystr+=','
        else :
            first = False 
        
        mystr+=str(el) 
        
    return mystr
    
if __name__ == '__main__':
    print os.getcwd()
    os.chdir("../../..")
    print os.getcwd()    
    properties = property_reader("config/master_configs/oyster_profile_ingestion.properties")
    result,details = validate_against_schema(properties,"D:/01_oyster/projects/data/oyster_feed/raw_data/pzn_sft/oyster_profile/oyster_profile.D2015321")
    
    if result :
        print "schema validation was Ok"
    else :
        print details
